# Домашнее задание к занятию 15.4 "Кластеры. Ресурсы под управлением облачных провайдеров"

> Организация кластера Kubernetes и кластера баз данных MySQL в отказоустойчивой архитектуре.
> Размещение в private подсетях кластера БД, а в public - кластера Kubernetes.

---
## Задание 1. Яндекс.Облако (обязательное к выполнению)

- [provider.tf](./15.4/yandex/provider.tf) - подключение и настройки провайдера
- [variables.tf](./15.4/yandex/variables.tf) - переменные
- [network.tf](./15.4/yandex/network.tf) - сеть
- [k8s.tf](./15.4/yandex/k8s.tf) - KMS ключ
- [serviceaccount.tf](./15.4/yandex/serviceaccount.tf) - сервис-аккаунт
- [mysql.tf](./15.4/yandex/mysql.tf) - кластер MySQL, ДБ и пользователь базы
- [kms.tf](./15.4/yandex/kms.tf) - кластер Kubernetes и группа узлов

Применяю манифест:
![15-4-1-terraform.png](./media/15-4-1-terraform.png)

> 1. Настроить с помощью Terraform кластер баз данных MySQL:
>       - Используя настройки VPC с предыдущих ДЗ, добавить дополнительно подсеть private в разных зонах, чтобы обеспечить отказоустойчивость 
>       - Разместить ноды кластера MySQL в разных подсетях
>       - Необходимо предусмотреть репликацию с произвольным временем технического обслуживания
>       - Использовать окружение PRESTABLE, платформу Intel Broadwell с производительностью 50% CPU и размером диска 20 Гб
>       - Задать время начала резервного копирования - 23:59
>       - Включить защиту кластера от непреднамеренного удаления
>       - Создать БД с именем `netology_db` c логином и паролем

1. Подсети
![15-4-1-vpc.png](./media/15-4-1-vpc.png)
1. Кластер MySQL
![15-4-1-mysq_cluster.png](./media/15-4-1-mysq_cluster.png)
1. Параметры кластера. Окружение PRESTABLE.
![15-4-1-mysql_overview.png](./media/15-4-1-mysql_overview.png)
Настроено техническое обслуживание в произвольное время и резервное копирование в 23:59. Используется платформа Intel Broadwell с производительностью 50% CPU и размером диска 20 Гб.
![15-4-1-mysql_overview2.png](./media/15-4-1-mysql_overview2.png)
1. Включена защита от удаления
![15-4-1-mysq_delete_protection.png](./media/15-4-1-mysq_delete_protection.png)
1. Хосты кластера, в разных подсетях.
![15-4-1-mysql_hosts.png](./media/15-4-1-mysql_hosts.png)
1. Отдельный пользователь `netology`
![15-4-1-mysql_user.png](./media/15-4-1-mysql_user.png)
1. База `netology_db`
![15-4-1-mysql_db.png](./media/15-4-1-mysql_db.png)

> 2. Настроить с помощью Terraform кластер Kubernetes
>       - Используя настройки VPC с предыдущих ДЗ, добавить дополнительно 2 подсети public в разных зонах, чтобы обеспечить отказоустойчивость
>       - Создать отдельный сервис-аккаунт с необходимыми правами 
>       - Создать региональный мастер kubernetes с размещением нод в разных 3 подсетях
>       - Добавить возможность шифрования ключом из KMS, созданного в предыдущем ДЗ
>       - Создать группу узлов состояющую из 3 машин с автомасштабированием до 6
>       - Подключиться к кластеру с помощью `kubectl`
>       - *Запустить микросервис phpmyadmin и подключиться к БД, созданной ранее
>       - *Создать сервис типы Load Balancer и подключиться к phpmyadmin. Предоставить скриншот с публичным адресом и подключением к БД
> 
> <details><summary>.</summary>
>
> Документация
> - [MySQL cluster](https://registry.terraform.io/providers/yandex-cloud/yandex/latest/docs/resources/mdb_mysql_cluster)
> - [Создание кластера kubernetes](https://cloud.yandex.ru/docs/managed-kubernetes/operations/kubernetes-cluster/kubernetes-cluster-create)
> - [K8S Cluster](https://registry.terraform.io/providers/yandex-cloud/yandex/latest/docs/resources/kubernetes_cluster)
> - [K8S node group](https://registry.terraform.io/providers/yandex-cloud/yandex/latest/docs/resources/kubernetes_node_group)
>
> </details>

Выполнить задание в точности не получилось, т.к. Яндекс позволяет создать группу нод с автоскейлом только в одной подсети:

![15-4-1-k8s_node_groups_autoscale_single_subnet.png](./media/15-4-1-k8s_node_groups_autoscale_single_subnet.png)

В остальном всё удалось:
1. Сервис-аккаунт
![15-4-1-service_account.png](./media/15-4-1-service_account.png)
1. KMS ключ
![15-4-1-kms.png](./media/15-4-1-kms.png)
1. Параметры кластера, сервис-аккаунт и ключ KMS используются
![15-4-1-k8s_overview.png](./media/15-4-1-k8s_overview.png)
Мастер - региональный. 
![15-4-1-k8s_overview2.png](./media/15-4-1-k8s_overview2.png)
1. Группа нод с автоскейлом от 3 до 6
![15-4-1-k8s_manage_nodes.png](./media/15-4-1-k8s_manage_nodes.png)
1. Ноды
![15-4-1-k8s_nodes.png](./media/15-4-1-k8s_nodes.png)
1. По [документации](https://cloud.yandex.ru/docs/managed-kubernetes/operations/connect/#kubectl-connect) подключаюсь к кластеру с `kubectl`
![15-4-1-kubectl.png](./media/15-4-1-kubectl.png)
1. Применяю [манифесты](./15.4/yandex/manifests/) `phpMyAdmin`:
    - [00-deployment.yml](./15.4/yandex/manifests/00-deployment.yml)
    - [10-service.yml](./15.4/yandex/manifests/10-service.yml)
![15-4-1-phpMyAdmin_apply_manifests.png](./media/15-4-1-phpMyAdmin_apply_manifests.png)
1. Трафик к сервису идёт через балансировщик
![15-4-1-LoadBalancer_IP.png](./media/15-4-1-LoadBalancer_IP.png)
1. Подключаюсь к вебке, в списке видно базу `netology_db`
![15-4-1-phpMyAdmin_web.png](./media/15-4-1-phpMyAdmin_web.png)

--- 
## Задание 2. Вариант с AWS (необязательное к выполнению)

Как и прошлые ДЗ блока, я сделал необязательную часть на Sber Cloud, т.к. не имею доступа к AWS.

Манифесты:
- [provider.tf](./15.4/sber/provider.tf) - провайдеры и их настройки (SberCloud и Local)
- [variables.tf](./15.4/sber/variables.tf) - переменные
- [compute.tf](./15.4/sber/compute.tf) - ssh ключ доступа к нодам
- [network.tf](./15.4/sber/network.tf) - сеть
- [rds.tf](./15.4/sber/rds.tf) - MySQL на мощностях Relational Database Service
- [k8s.tf](./15.4/sber/k8s.tf) - Kubernetes на мощностях Cloud Container Engine
- [loadbalancer.tf](./15.4/sber/loadbalancer.tf) - балансировщик для Кубера
- [local.tf](./15.4/sber/local.tf) - создание манифестов для размещения phpMyAdmin в Кубере, заполняются параметры подключения к MySQL и IP балансировщика

Применяю манифесты:
![15-4-2-terraform.png](./media/15-4-2-terraform.png)

> 1. Настроить с помощью terraform кластер EKS в 3 AZ региона, а также RDS на базе MySQL с поддержкой MultiAZ для репликации и создать 2 readreplica для работы:
>       - Создать кластер RDS на базе MySQL
>       - Разместить в Private subnet и обеспечить доступ из public-сети c помощью security-group
>       - Настроить backup в 7 дней и MultiAZ для обеспечения отказоустойчивости
>       - Настроить Read prelica в кол-ве 2 шт на 2 AZ.

1. Кластер MYSQL
![15-4-2-mysql_cluster.png](./media/15-4-2-mysql_cluster.png)
Топология
![15-4-2-mysql_topology.png](./media/15-4-2-mysql_topology.png)
Обзор параметров
![15-4-2-mysql_overview.png](./media/15-4-2-mysql_overview.png)
1. Сабнеты, добавлено несколько сетей `private` в разных зонах доступности
![15-4-2-subnets.png](./media/15-4-2-subnets.png)
1. Группы безопасности - `n15` создана для задачи в `network.tf`, три созданы автоматический
![15-4-2-secgroup_inbound.png](./media/15-4-2-secgroup_inbound.png)
Inbound правила группы безопасности `n15` в ней разрешен доступ к MySQL для сети `10.0.0.0/8`
![15-4-2-security_groups.png](./media/15-4-2-security_groups.png)

> 2. Создать кластер EKS на базе EC2:
>       - С помощью terraform установить кластер EKS на 3 EC2-инстансах в VPC в public-сети
>       - Обеспечить доступ до БД RDS в private-сети
>       - С помощью kubectl установить и запустить контейнер с phpmyadmin (образ взять из docker hub) и проверить подключение к БД RDS
>       - Подключить ELB (на выбор) к приложению, предоставить скрин
> 
> <details><summary>.</summary>
>
> Документация
> - [Модуль EKS](https://learn.hashicorp.com/tutorials/terraform/eks)
>
> </details>

1. Кластер Kubernetes
![15-4-2-k8s_cluster.png](./media/15-4-2-k8s_cluster.png)
Обзор параметров, видно что кластер доступен по адресу https://188.72.108.81:5443
![15-4-2-k8s_cluster_overview.png](./media/15-4-2-k8s_cluster_overview.png)
1. Ноды. Я сделал две, т.к. ограничен лимитами облака по памяти.
![15-4-2-k8s_nodes.png](./media/15-4-2-k8s_nodes.png)
1. `kubectl`, подключение к кластеру работает
![15-4-2-k8s_kubectl_info.png](./media/15-4-2-k8s_kubectl_info.png)
1. Балансировщик, IP `37.18.100.189` с листнером `k8s`
![15-4-2-lb.png](./media/15-4-2-lb.png)
1. Применяю манифесты
![15-4-2-k8s_kubectl_apply.png](./media/15-4-2-k8s_kubectl_apply.png)
Сервис для phpMyAdmin доступен по адресу балансировщика
![15-4-2-k8s_kubectl_service_lb.png](./media/15-4-2-k8s_kubectl_service_lb.png)
1. Открыл страничку phpMyAdmin в браузере
![15-4-2-pma_web.png](./media/15-4-2-pma_web.png)